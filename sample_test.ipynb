{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yXBTtPVJDnCqtYdX10Ma8izpcsTxZTMR",
      "authorship_tag": "ABX9TyPih6O5e//7XTB6pDjZG7BX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jellyXuuuuu/CovidNetDeepLearning/blob/main/sample_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp 'drive/MyDrive/covid/requirements.txt' ."
      ],
      "metadata": {
        "id": "ka3aaDvyTbW3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install -r requirements.txt"
      ],
      "metadata": {
        "id": "Mkneg79ITy9C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw_ZL_iCLX2l",
        "outputId": "8b4c4d07-55b4-4a0f-a0e8-9598e2179f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-gdcm in /usr/local/lib/python3.7/dist-packages (3.0.19)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.7/dist-packages (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install python-gdcm\n",
        "!pip3 install pydicom"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m32Q0IImVN8o",
        "outputId": "fa558404-2a65-4dc9-b54e-6b6d7081d1d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.49.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (2.0.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.1.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import pydicom\n",
        "# import dicom\n",
        "from pydicom.pixel_data_handlers import apply_modality_lut, apply_voi_lut\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "AkT__BReLfUu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.py\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def crop_top(img, percent=0.15):\n",
        "    offset = int(img.shape[0] * percent)\n",
        "    return img[offset:]\n",
        "\n",
        "def central_crop(img):\n",
        "    size = min(img.shape[0], img.shape[1])\n",
        "    offset_h = int((img.shape[0] - size) / 2)\n",
        "    offset_w = int((img.shape[1] - size) / 2)\n",
        "    return img[offset_h:offset_h + size, offset_w:offset_w + size]\n",
        "\n",
        "def process_image_file(filepath, size, top_percent=0.08, crop=True):\n",
        "    img = cv2.imread(filepath)\n",
        "    # print(\"filepath\", filepath)\n",
        "    img = crop_top(img, percent=top_percent)\n",
        "    if crop:\n",
        "        img = central_crop(img)\n",
        "    img = cv2.resize(img, (size, size))\n",
        "    return img\n",
        "\n",
        "def process_image_file_medusa(filepath, size):\n",
        "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (size, size))\n",
        "    img = img.astype('float64')\n",
        "    img -= img.mean()\n",
        "    img /= img.std()\n",
        "    return np.expand_dims(img, -1)\n",
        "\n",
        "def random_ratio_resize(img, prob=0.3, delta=0.1):\n",
        "    if np.random.rand() >= prob:\n",
        "        return img\n",
        "    ratio = img.shape[0] / img.shape[1]\n",
        "    ratio = np.random.uniform(max(ratio - delta, 0.01), ratio + delta)\n",
        "\n",
        "    if ratio * img.shape[1] <= img.shape[1]:\n",
        "        size = (int(img.shape[1] * ratio), img.shape[1])\n",
        "    else:\n",
        "        size = (img.shape[0], int(img.shape[0] / ratio))\n",
        "\n",
        "    dh = img.shape[0] - size[1]\n",
        "    top, bot = dh // 2, dh - dh // 2\n",
        "    dw = img.shape[1] - size[0]\n",
        "    left, right = dw // 2, dw - dw // 2\n",
        "\n",
        "    if size[0] > 480 or size[1] > 480:\n",
        "        print(img.shape, size, ratio)\n",
        "\n",
        "    img = cv2.resize(img, size)\n",
        "    img = cv2.copyMakeBorder(img, top, bot, left, right, cv2.BORDER_CONSTANT,\n",
        "                             (0, 0, 0))\n",
        "\n",
        "    if img.shape[0] != 480 or img.shape[1] != 480:\n",
        "        raise ValueError(img.shape, size)\n",
        "    return img\n",
        "\n",
        "_augmentation_transform = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=(0.9, 1.1),\n",
        "    zoom_range=(0.85, 1.15),\n",
        "    fill_mode='constant',\n",
        "    cval=0.,\n",
        ")\n",
        "\n",
        "def apply_augmentation(img):\n",
        "    img = random_ratio_resize(img)\n",
        "    img = _augmentation_transform.random_transform(img)\n",
        "    return img\n",
        "\n",
        "def _process_csv_file(file):\n",
        "    with open(file, 'r') as fr:\n",
        "        files = fr.readlines()\n",
        "    return files\n",
        "\n",
        "\n",
        "class BalanceCovidDataset(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            data_dir,\n",
        "            csv_file,\n",
        "            is_training=True,\n",
        "            batch_size=8,\n",
        "            medusa_input_shape=(256, 256),\n",
        "            input_shape=(480, 480),\n",
        "            n_classes=2,\n",
        "            num_channels=3,\n",
        "            mapping={\n",
        "                'negative': 0,\n",
        "                'positive': 1,\n",
        "            },\n",
        "            shuffle=True,\n",
        "            augmentation=apply_augmentation,\n",
        "            covid_percent=0.5,\n",
        "            class_weights=[1., 1.],\n",
        "            top_percent=0.08,\n",
        "            is_severity_model=False,\n",
        "            is_medusa_backbone=False,\n",
        "    ):\n",
        "        'Initialization'\n",
        "        self.datadir = data_dir\n",
        "        self.dataset = _process_csv_file(csv_file)\n",
        "        self.is_training = is_training\n",
        "        self.batch_size = batch_size\n",
        "        self.N = len(self.dataset)\n",
        "        self.medusa_input_shape = medusa_input_shape\n",
        "        self.input_shape = input_shape\n",
        "        self.n_classes = n_classes\n",
        "        self.num_channels = num_channels\n",
        "        self.mapping = mapping\n",
        "        self.shuffle = shuffle\n",
        "        self.covid_percent = covid_percent\n",
        "        self.class_weights = class_weights\n",
        "        self.n = 0\n",
        "        self.augmentation = augmentation\n",
        "        self.top_percent = top_percent\n",
        "        self.is_severity_model = is_severity_model\n",
        "        self.is_medusa_backbone = is_medusa_backbone\n",
        "\n",
        "        # If using MEDUSA backbone load images without crop\n",
        "        if self.is_medusa_backbone:\n",
        "            self.load_image = partial(process_image_file, top_percent=0, crop=False)\n",
        "        else:\n",
        "            self.load_image = process_image_file\n",
        "\n",
        "        datasets = {}\n",
        "        for key in self.mapping.keys():\n",
        "            datasets[key] = []\n",
        "\n",
        "        for l in self.dataset:\n",
        "            datasets[l.split()[2]].append(l)\n",
        "        \n",
        "        if self.is_severity_model:\n",
        "            self.datasets = [\n",
        "                datasets['level2'], datasets['level1']\n",
        "            ]\n",
        "        elif self.n_classes == 2:\n",
        "            self.datasets = [\n",
        "                datasets['negative'], datasets['positive']\n",
        "            ]\n",
        "        elif self.n_classes == 3:\n",
        "            self.datasets = [\n",
        "                datasets['normal'] + datasets['pneumonia'],\n",
        "                datasets['COVID-19'],\n",
        "            ]\n",
        "        else:\n",
        "            raise Exception('Only binary or 3 class classification currently supported.')\n",
        "        print(len(self.datasets[0]), len(self.datasets[1]))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __next__(self):\n",
        "        # Get one batch of data\n",
        "        model_inputs = self.__getitem__(self.n)\n",
        "        # Batch index\n",
        "        self.n += 1\n",
        "\n",
        "        # If we have processed the entire dataset then\n",
        "        if self.n >= self.__len__():\n",
        "            self.on_epoch_end()\n",
        "            self.n = 0\n",
        "\n",
        "        return model_inputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.datasets[0]) / float(self.batch_size)))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        if self.shuffle == True:\n",
        "            for v in self.datasets:\n",
        "                np.random.shuffle(v)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = np.zeros((self.batch_size, *self.input_shape, self.num_channels))\n",
        "        batch_y = np.zeros(self.batch_size)\n",
        "\n",
        "        if self.is_medusa_backbone:\n",
        "            batch_sem_x = np.zeros((self.batch_size, *self.medusa_input_shape, 1))\n",
        "\n",
        "        batch_files = self.datasets[0][idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        # upsample covid cases\n",
        "        covid_size = max(int(len(batch_files) * self.covid_percent), 1)\n",
        "        covid_inds = np.random.choice(np.arange(len(batch_files)),\n",
        "                                      size=covid_size,\n",
        "                                      replace=False)\n",
        "        covid_files = np.random.choice(self.datasets[1],\n",
        "                                       size=covid_size,\n",
        "                                       replace=False)\n",
        "        for i in range(covid_size):\n",
        "            batch_files[covid_inds[i]] = covid_files[i]\n",
        "\n",
        "        for i in range(len(batch_files)):\n",
        "            sample = batch_files[i].split()\n",
        "\n",
        "            if self.is_training:\n",
        "                folder = 'train'\n",
        "            else:\n",
        "                folder = 'test'\n",
        "\n",
        "            image_file = os.path.join(self.datadir, folder, sample[1])\n",
        "            x = self.load_image(\n",
        "                image_file,\n",
        "                self.input_shape[0],\n",
        "                top_percent=self.top_percent,\n",
        "            )\n",
        "\n",
        "            if self.is_training and hasattr(self, 'augmentation'):\n",
        "                x = self.augmentation(x)\n",
        "\n",
        "            x = x.astype('float32') / 255.0\n",
        "\n",
        "            if self.is_medusa_backbone:\n",
        "                sem_x = process_image_file_medusa(image_file, self.medusa_input_shape[0])\n",
        "                batch_sem_x[i] = sem_x\n",
        "            \n",
        "            y = self.mapping[sample[2]]\n",
        "\n",
        "            batch_x[i] = x\n",
        "            batch_y[i] = y\n",
        "\n",
        "        class_weights = self.class_weights\n",
        "        weights = np.take(class_weights, batch_y.astype('int64'))\n",
        "        batch_y = keras.utils.to_categorical(batch_y, num_classes=self.n_classes)\n",
        "\n",
        "        if self.is_medusa_backbone:\n",
        "            return batch_sem_x, batch_x, batch_y, weights, self.is_training\n",
        "        else:\n",
        "            return batch_x, batch_y, weights, self.is_training\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19x8J7S1SbCC",
        "outputId": "468d33d2-9e8d-4571-e6f3-a525248069e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r 'drive/MyDrive/covid/labels/' ."
      ],
      "metadata": {
        "id": "OFgXNpMmSpSb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r 'drive/MyDrive/covid/models/' ."
      ],
      "metadata": {
        "id": "ira5CKpiV3MD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy test image file\n",
        "!cp -r 'drive/MyDrive/data' .\n",
        "!cp 'drive/MyDrive/covid/testimage/0a8d486f-1aa6-4fcf-b7be-4bf04fc8628b.png' './data/test'"
      ],
      "metadata": {
        "id": "EJ50A_y-1kD6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r 'drive/MyDrive/covid/assets/' ."
      ],
      "metadata": {
        "id": "LL5Uzrhn78Oy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "NkAgky_C6dht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os, argparse\n",
        "\n",
        "# from data import (\n",
        "#     process_image_file, \n",
        "#     process_image_file_medusa,\n",
        "# )\n",
        "\n",
        "# To remove TF Warnings\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "\n",
        "def print_metrics(y_test, pred, mapping):\n",
        "    matrix = confusion_matrix(y_test, pred)\n",
        "    matrix = matrix.astype('float')\n",
        "    print(matrix)\n",
        "\n",
        "    class_acc = [matrix[i,i]/np.sum(matrix[i,:]) if np.sum(matrix[i,:]) else 0 for i in range(len(matrix))]\n",
        "    ppvs = [matrix[i,i]/np.sum(matrix[:,i]) if np.sum(matrix[:,i]) else 0 for i in range(len(matrix))]\n",
        "\n",
        "    print(\"class_acc\", class_acc)\n",
        "    print(\"ppvs\", ppvs)\n",
        "\n",
        "    # print('Sens', ', '.join('{}: {:.3f}'.format(cls.capitalize(), class_acc[i]) for cls, i in mapping.items()))\n",
        "    # print('PPV', ', '.join('{}: {:.3f}'.format(cls.capitalize(), ppvs[i]) for cls, i in mapping.items()))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # args = []\n",
        "    '''\n",
        "    python eval.py \\\n",
        "    --weightspath models/COVIDNet-CXR-3 \\\n",
        "    --metaname model.meta \\\n",
        "    --ckptname model \\\n",
        "    --n_classes 2 \\\n",
        "    --testfile labels/test_COVIDx9B.txt \\\n",
        "    --out_tensorname softmax/Softmax:0 \\\n",
        "    --is_medusa_backbone\n",
        "    '''\n",
        "\n",
        "    args_weightspath = 'models/COVIDNet-CXR-2' \n",
        "    args_metaname = 'model.meta'\n",
        "    args_ckptname = 'model'\n",
        "    args_n_classes = 2\n",
        "\n",
        "    args_testfolder = 'data/test'\n",
        "\n",
        "    args_input_size = 480\n",
        "\n",
        "    args_trainfile = 'labels/train_COVIDx9B.txt'\n",
        "    args_testfile = 'labels/test_COVIDx9B.txt'\n",
        "    args_in_tensorname = 'input_1:0'\n",
        "    args_out_tensorname = 'norm_dense_2/Softmax:0'\n",
        "    args_logit_tensorname = 'norm_dense_2/MatMul:0'\n",
        "    args_is_severity_model = False\n",
        "    args_is_medusa_backbone = True\n",
        "\n",
        "\n",
        "    args_in_tensorname_medusa = 'input_1:0'\n",
        "    args_input_size_medusa = 256\n",
        "    args_top_percent = 0.08\n",
        "    args_imagepath = 'assets/ex-covid.jpeg'\n",
        "    \n",
        "    sess = tf.compat.v1.Session()\n",
        "    # sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "    # tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "    # tf.get_default_graph()\n",
        "    tf.compat.v1.get_default_graph()\n",
        "    saver = tf.compat.v1.train.import_meta_graph(os.path.join(args_weightspath, args_metaname))\n",
        "    saver.restore(sess, os.path.join(args_weightspath, args_ckptname))\n",
        "\n",
        "    graph = tf.get_default_graph()\n",
        "\n",
        "    image_tensor = graph.get_tensor_by_name(args_in_tensorname)\n",
        "    pred_tensor = graph.get_tensor_by_name(args_out_tensorname)\n",
        "\n",
        "\n",
        "\n",
        "    # print(\"GRAPH: -------------------\")\n",
        "    # for op in graph.get_operations():\n",
        "    #   print(op.name)\n",
        "\n",
        "    # file = open(args_testfile, 'r')\n",
        "    # testfile = file.readlines()\n",
        "\n",
        "    if args_is_severity_model:\n",
        "        # For COVIDNet CXR-S training with COVIDxSev level 1 and level 2 air space seveirty grading\n",
        "        mapping = {'level2': 0, 'level1': 1}\n",
        "        inv_mapping = {0: 'level2', 1: 'level1'}\n",
        "    elif args_n_classes == 2:\n",
        "        # For COVID-19 positive/negative detection\n",
        "        mapping = {'negative': 0, 'positive': 1}\n",
        "        inv_mapping = {0: 'negative', 1: 'positive'}\n",
        "    elif args_n_classes == 3:\n",
        "        # For detection of no pneumonia/non-COVID-19 pneumonia/COVID-19 pneumonia\n",
        "        mapping = {'normal': 0, 'pneumonia': 1, 'COVID-19': 2}\n",
        "        inv_mapping = {0: 'normal', 1: 'pneumonia', 2: 'COVID-19'}\n",
        "    else:\n",
        "        raise Exception('''COVID-Net currently only supports 2 class COVID-19 positive/negative detection\n",
        "            or 3 class detection of no pneumonia/non-COVID-19 pneumonia/COVID-19 pneumonia''')\n",
        "\n",
        "    print(\"mapping\", mapping)\n",
        "    mapping_keys = list(mapping.keys())\n",
        "\n",
        "\n",
        "    # //////////////////////////////////\n",
        "\n",
        "\n",
        "    # y_test = []\n",
        "    # pred = []\n",
        "\n",
        "    # # for i in range(len(testfile)):\n",
        "    # # line = testfile[0].split()\n",
        "    # lines = \"0a8d486f-1aa6-4fcf-b7be-4bf04fc8628b 0a8d486f-1aa6-4fcf-b7be-4bf04fc8628b.png negative rsna\"\n",
        "    # line = lines.split()\n",
        "    # image_file = os.path.join(args_testfolder, line[1])\n",
        "    # # image_file = os.path.join(args_testfolder, \"0a8d486f-1aa6-4fcf-b7be-4bf04fc8628b.png\")  #0a8d486f-1aa6-4fcf-b7be-4bf04fc8628b\n",
        "    \n",
        "    # '''\n",
        "    # 0a8d486f-1aa6-4fcf-b7be-4bf04fc8628b 0a8d486f-1aa6-4fcf-b7be-4bf04fc8628b.png negative rsna\n",
        "    # '''\n",
        "\n",
        "    # print(\"testfolder line1, image\", image_file)\n",
        "    \n",
        "    # y_test.append(mapping[line[2]])\n",
        "\n",
        "    # x = process_image_file(image_file, args_input_size, top_percent=0.08)\n",
        "    # x = x.astype('float32') / 255.0\n",
        "    # data_tensor = tf.get_default_graph().get_tensor_by_name(\"input_1:0\")  # /////////////////////????input_2:0\n",
        "    # feed_dict = {data_tensor: np.expand_dims(x, axis=0)}\n",
        "\n",
        "    # # print(\"Not is_medusa_backbone\")\n",
        "\n",
        "    # \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
        "\n",
        "    if args_is_medusa_backbone:\n",
        "        x = process_image_file(args_imagepath, args_input_size, top_percent=0, crop=False)\n",
        "        x = x.astype('float32') / 255.0\n",
        "        medusa_image_tensor = graph.get_tensor_by_name(args_in_tensorname_medusa)\n",
        "        medusa_x = process_image_file_medusa(args_imagepath, args_input_size_medusa)\n",
        "        feed_dict = {\n",
        "                    medusa_image_tensor: np.expand_dims(medusa_x, axis=0),\n",
        "                    image_tensor: np.expand_dims(x, axis=0),\n",
        "                } \n",
        "    else:\n",
        "        x = process_image_file(args_imagepath, args_input_size, top_percent=args_top_percent)\n",
        "        x = x.astype('float32') / 255.0\n",
        "        feed_dict = {image_tensor: np.expand_dims(x, axis=0)}\n",
        "\n",
        "   \n",
        "\n",
        "    print(\"feed_dict\", feed_dict)\n",
        "    \n",
        "    \n",
        "    pred = sess.run(pred_tensor, feed_dict=feed_dict)\n",
        "    \n",
        "    # pred.append(np.array(sess.run(args_out_tensorname, feed_dict=feed_dict)).argmax(axis=1))  ############\n",
        "    # print(\"sess_run\", sess.run(args_out_tensorname, feed_dict=feed_dict))\n",
        "    # print(\"np\", np.array(sess.run(args_out_tensorname, feed_dict=feed_dict))) # [[9.9999774e-01 2.2671331e-06]]\n",
        "    \n",
        "    # print(\"argmax\", np.array(sess.run(args_out_tensorname, feed_dict=feed_dict)).argmax(axis=1))\n",
        "    # print(\"pred[0]\", pred[0])  # index of the maximum, in this case, the first arg is bigger than the second\n",
        "    \n",
        "    \n",
        "    # y_test = np.array(y_test)\n",
        "    # pred = np.array(pred)\n",
        "\n",
        "    # print_metrics(y_test, pred, mapping)\n",
        "\n",
        "    print(\"pred\", pred)\n",
        "\n",
        "    print('Prediction: {}'.format(inv_mapping[pred.argmax(axis=1)[0]]))\n",
        "    print('Confidence')\n",
        "    print(' '.join('{}: {:.3f}'.format(cls.capitalize(), pred[0][i]) for cls, i in mapping.items()))\n",
        "    print('**DISCLAIMER**')\n",
        "    print('Do not use this prediction for self-diagnosis. You should check with your local authorities for the latest advice on seeking medical assistance.')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpUH23ZFQ77s",
        "outputId": "bcb1d13b-8840-4612-b35a-c1970b0ae67e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mapping {'negative': 0, 'positive': 1}\n",
            "feed_dict {<tf.Tensor 'input_1:0' shape=(?, 480, 480, 3) dtype=float32>: array([[[[0.72156864, 0.72156864, 0.72156864],\n",
            "         [0.7176471 , 0.7176471 , 0.7176471 ],\n",
            "         [0.7137255 , 0.7137255 , 0.7137255 ],\n",
            "         ...,\n",
            "         [0.67058825, 0.67058825, 0.67058825],\n",
            "         [0.6627451 , 0.6627451 , 0.6627451 ],\n",
            "         [0.6627451 , 0.6627451 , 0.6627451 ]],\n",
            "\n",
            "        [[0.7372549 , 0.7372549 , 0.7372549 ],\n",
            "         [0.7176471 , 0.7176471 , 0.7176471 ],\n",
            "         [0.7137255 , 0.7137255 , 0.7137255 ],\n",
            "         ...,\n",
            "         [0.5254902 , 0.5254902 , 0.5254902 ],\n",
            "         [0.5254902 , 0.5254902 , 0.5254902 ],\n",
            "         [0.5254902 , 0.5254902 , 0.5254902 ]],\n",
            "\n",
            "        [[0.65882355, 0.65882355, 0.65882355],\n",
            "         [0.63529414, 0.63529414, 0.63529414],\n",
            "         [0.627451  , 0.627451  , 0.627451  ],\n",
            "         ...,\n",
            "         [0.16862746, 0.16862746, 0.16862746],\n",
            "         [0.16470589, 0.16470589, 0.16470589],\n",
            "         [0.16470589, 0.16470589, 0.16470589]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         ...,\n",
            "         [0.01960784, 0.01960784, 0.01960784],\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157]],\n",
            "\n",
            "        [[0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         ...,\n",
            "         [0.01568628, 0.01568628, 0.01568628],\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157]],\n",
            "\n",
            "        [[0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         ...,\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157],\n",
            "         [0.00392157, 0.00392157, 0.00392157]]]], dtype=float32)}\n",
            "Prediction: negative\n",
            "Confidence\n",
            "Negative: 0.924 Positive: 0.076\n",
            "**DISCLAIMER**\n",
            "Do not use this prediction for self-diagnosis. You should check with your local authorities for the latest advice on seeking medical assistance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jipRY9JvhZC7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7RPiCUtUuoj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print( tf.__version__ )"
      ],
      "metadata": {
        "id": "aei1EgnVU938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5a73c6-f910-4474-a0cd-8e643cf5bc77"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbSdegjgVtFg"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}